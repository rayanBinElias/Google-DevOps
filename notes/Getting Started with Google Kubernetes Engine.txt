Module 1: Introcution to Google Cloud
  - The first section of this course introduces cloud computing concepts. 
  Learners explore fundamental terminology, the Google Cloud network, 
  how Google Cloud resources are organized in an hierarchy for management, 
  and the tools available to connect to Google Cloud for allocating, changing, and releasing resources.

  Learning Objectives
    - Identify Google Cloud services and their function.
    - Choose the right Google Cloud services to create your own cloud solution.
    - Define the purpose of and use cases for Identity and Access Management (IAM).
    - Identify how costs can be managed in the resource hierarchy.
    - Use the Google Cloud console and Cloud Shell to create VMs, service accounts, and buckets.

  Introduction
    GKE
      - managed service for kb8s

    kb8s
      - orchestration framework for running containerized app in production at scale

    containers
      - way to package and run code that's more efficient than VM

  Cloud computing and Google Cloud
    Cloud computing 
      - a way of using IT that has these 5 equally improtant traits:
      
      1. On-demand Self-service
        - no human intervention needed to get resources
        - You can quickly get more resources when you need them.
      2. Broad network access
        - access from anywhere
        - Resources can be allocated automatically.
      3. Resource Pooling
        - provider shares resources to customers
        -  You share resources from a large pool that enables economies of scale.
      4. Rapid elasticity
        - get more resources quickly as needed
        - When customers need more resources, they can get more. When they need less, they can scale back.
      5. Measured service
        - pay only for what you consume

  Google cloud compute offerings
     Compute services
      1. Compute Engine
        - a managed environment for deploying VM instance
        - infra as a service solution
        6- provides max flex for people who prefer to manage server instance themselves
        - IaaS offerings
        - predefined and customized VMs
        - persistent disks and local SSDs
        - managed instance groups
        - per second billing

      2. Google kubernetes Engine(GKE)
        - a managed environment for deploying containerized applications
        - built ontop of compute engine
        - way to orchestrate code in containers.
        - lets you run containerized app on cloud envi that google manages for you under your admin control
    
      3. App Engine
        - a fully managed serverless platform for deploying applications
        - platform as a service framework(PaaS)
        - a managed compute platform that enables you to deploy and scale stateless containers on google cloud scalable infra.
        - bind code to libraries
        - focused on app logic/code
        - deploys required infrastructure
          - JAVA
          - Node.json
          - python
          - php
          - c#
          - .net
          - ruby
          - go
        - version control + traffic splitting
        - Usecases:
          - want to focus on writing code
          - want to focus on building app instead of deploying and managing the env
          - don't need to build a highly reliable and scalable infra

          1. website
          2. mobile and gaming backends
          3. restful API

      5. Cloud Functions
        - a fully managed serverless platform for deploying event-driven functions
        - function as a service
        - event-based, asynch compute solution
        - exec code in response to events
        - deploys the computing capacity to run code
        - can connect and extend cloud services
        - bills to nearest 100 ms

        Common Usecases
          1. part of microservices app architecture
          2. used to build simple, serverless mobile or IoT backends or Integrate w/ third-party services and apis
          3. can be part of intelligent app such as VA, video or image analysis, and sentiment analysis
      
      6. Cloud Run
        - a managed compute platform
        - runs statless containers
        - serverless
        - built on knative
        - it's fast
        - charges only for resources used
        - bills to nearest 100 ms

  The google network
    - 40% world internet market share

    Notes
      - highest possible throughput
      - lowest possible latencies
      - 100+ CDN nodes worldwide
      - high demand content is cached for quicker access

    Five Major Geographic Locations
      1. North America
      2. South America
      3. Asia
      5. Australia

    App location affects:
      1. availability
      2. durability
      3. latency

  Resource management
    Latency under 1ms
      Regiona, Zone, Network Edge Locations
    
    1. Zonal resources operate exclusively in a single zone
      - compute engine
      - persistent disk
      - gke node

    2. Regional resources span multiple zones
      - regional GKE cluster
      - firestore

    3. Global resources can be managed across multiple regions
      - http(s) load balancer
      - VPC

    4. Project
      - base-level organizing entity for creating and using resources, services, managing billing, APIs and permissions.
        - any resources must reside/belong to a project
      - project logically organize resources while zones and regions physically organize them
      - can be recovered from accidental deletions
      - identified by unique project ID, name and number
        - project ID
          - globally unique
          - immutable
          - assigned by GC byt mutable during creation

        - project name
          - need not be unique
          - chosen by you
          - mutable

        - project number
          - globally unique
          - assigned by google cloud
          - immutable

      - billing is at project level and managed separately
      - projects can have diff owners and users
      - projects hold resources, each of which belongs to just one project
      - projects are separate entities under the org node

    5. Use folders to reflect hierarchy like dept -> team and apply policies
      - can nest folders
    
    6. Organization
      - root node of google cloud resource hierarchy
      - fix org ID
      - changeable display name

    7. IAM
      - fine-tune access control to all the Google Cloud Resources
      - Admin can applu policies that define who can do whatt on which resources
        - who(google acount, service acount, google group, cloud identity domain)
          - principal
        - can do what
          - IAM role to IAM group
        - on which resources

      - Shared Resoponsibility
        - "If you can configure or store it, you're responsible for securing it."

        1. cloud provider
          - hardware
          - networks
          - physical security

        2. customer
          - configurations
          - access policies
          - user data

    8. Policies inhireted from root to downward level

    9. Resource hierarchy matters because Google Cloud shared security model
      - google is responsible for manging its infra security
      - your are responsible for securing your Data
      - google helps with best practices, templates, products and solutions

      Resoponsibility Components
        Content
        Usage
        deployment
        Web application security
        Identity
        Operations
        Access and authentication
        network security
        OS, data and Content
        audit logging
        network
        storage and encryption
        hardware

    Note

  Billing
    - project level

    How billing works?
      - billing account pays for project resources
      - billing account is linked to zero or more projects
      - billing acct can be charged automatically 
      or invoiced every month or at threshold limit
      - subaccounts can be used for separate billing for projects

    How to keep your billing under control
      1. budgets 
        - billing account or project level
      2. alerts
        - notify when costs approach your budget limit
        
      3. reports
        - visual tool to monitor expenditure based on project or services

        billing export
        - BigQuery
        - cloud looker studio
          - visualize data

      4. quotas
        -  designed to prevent the over-consumption of resources because of an error or a malicious attack

      Cloud implements quotas
        - limits unforeseen extra billing charges
        - prevent overconsumption of resources because of an error/malicious attack
        - project level 
      
        Types 
          1. Rate quotas
            - resets after specif time
            - not limit rate of calls to app running in GKE but calls to admin config of GKE clusters
            
            sample:
              GKE API: 3000 req per min 
          
          2. Allocation quotas
            - govern number of resources you can have in your projects
            - doesn't reset at intervals
            
            sample:
              - 15 networks per project
        
      Note:
        - quouta may increase automatically based on Usage
        - can lower quotas
        - some quyoutas are fixed fo all customers

  Interacting with Google Cloud
    Ways to interact w/ google cloud
      1. Google cloud console
        - web user interface to manage all google cloud resources
      
      2. Cloud SDK and Cloud Shell
        - CLI access to your cloud resources directly from your browser
          - gcloud
            - main cli for google cloud products and services
          - kubectl
          - gsutil
            - provides access to GCS from command line
          - bq
            - cli for bq
        
        Cloud shell
          - ephmeral GCE VM instance
          - built-in authorization fro access to cloud console projects and resources
          - debian VM
          - persistent 5 gb home dir

          Cloud shell code Editor
            - a tool for editing files inside of your cloud shell env in real-time w/in web browser
      
      3. Cloud Console mobile app
        - for iOS and Android
        - start, stop and use ssh to connect to GCE instances
        - get up-to-date billing infor and alerts
        - set up customizable grapsh that show key metrics
        - no additional charge

      4. Rest-based API
        - for customer app so that code you write can control them(google api explorer)

  Qwiklab: accessing the cloud console and cloud Shell
     In this lab, you become familiar with Google Cloud's web-based interface. Two integrated environments are available:
      - A GUI environment called the Google Cloud console
      - A command-line interface called Cloud Shell, which has the commands from the Cloud SDK pre-installed

    Objectives
      In this lab, you learn how to perform the following tasks:

        1. Learn how to access the Google Cloud console and Cloud Shell
        2. Become familiar with the Google Cloud console
        3. Become familiar with Cloud Shell features, including the Cloud Shell Editor
        4. Use the Google Cloud console and Cloud Shell to create buckets and VMs and service accounts
        5. Perform other commands in Cloud Shell

    Cloud Shell provides the following features and capabilities:
      - Temporary Compute Engine VM
      - Command-line access to the instance through a browser
      - 5 GB of persistent disk storage ($HOME dir)
      - Preinstalled Cloud SDK and other tools
      - gcloud: for working with Compute Engine, Google Kubernetes Engine (GKE), and many Google Cloud services
      - gcloud storage and gsutil: for working with Cloud Storage
      - kubectl: for working with GKE and Kubernetes
      - bq: for working with BigQuery
      - Language support for Java, Go, Python, Node.js, PHP, and Ruby
      - Web preview functionality
      - Built-in authorization for access to resources and instances

      Note:
        - After one hour of inactivity, the Cloud Shell instance is recycled. Only the /home directory persists. Any changes made to the system configuration, including environment variables, are lost between sessions.
        - When you are working in the Cloud Shell or writing scripts, creating environment variables is a good practice. You can easily and consistently reuse these environment variables, which makes your work less error-prone.

      //create a bucket
        gcloud storage buckets create gs://$MY_BUCKET_NAME_2 --location=us-central1

      //set gcloud zone configuration
        gcloud config set compute/zone $MY_ZONE

      // verify config
        gcloud config list

      //create second VM
        gcloud compute instances create $MY_VMNAME \
        --machine-type "e2-standard-2" \
        --image-project "debian-cloud" \
        --image-family "debian-11" \
        --subnet "default"

      //verify list all VMs
        gcloud compute instances list

      //create second service accounts
        gcloud iam service-accounts create test-service-account2 --display-name "test-service-account2"

      //grant the second service account the viewer role
        gcloud projects add-iam-policy-binding $GOOGLE_CLOUD_PROJECT --member serviceAccount:test-service-account2@${GOOGLE_CLOUD_PROJECT}.iam.gserviceaccount.com --role roles/viewer
      
      //Copy a picture of a cat from a Google-provided Cloud Storage bucket to your Cloud Shell:
        gcloud storage cp gs://cloud-training/ak8s/cat.jpg cat.jpg

      //upload image to bucket 1
        gcloud storage cp cat.jpg gs://$MY_BUCKET_NAME_1

      // upload image from bucket 1 to bucket 2
        gcloud storage cp gs://$MY_BUCKET_NAME_1/cat.jpg gs://$MY_BUCKET_NAME_2/cat.jpg

      //Set the access control list for a Cloud Storage object
        // view acl current
          gsutil acl get gs://$MY_BUCKET_NAME_1/cat.jpg  > acl.txt cat acl.txt

        // set to private
          gsutil acl set private gs://$MY_BUCKET_NAME_1/cat.jpg

        //verify
          gsutil acl get gs://$MY_BUCKET_NAME_1/cat.jpg  > acl-2.txt cat acl-2.txt

      // Authenticate as a service account in Cloud Shell
        gcloud auth activate-service-account --key-file credentials.json

        //verify
          gcloud config list
        
        //list auth list
          gcloud auth list

        // verify test-service-account cannot access the cat.jpg file i
      
      //switch back
        gcloud config set account $USERNAME

        //verify
          gcloud storage cp gs://$MY_BUCKET_NAME_1/cat.jpg ./copy2-of-cat.jpg
          
      //Make the first Cloud Storage bucket readable by everyone, including unauthenticated users:
        gsutil iam ch allUsers:objectViewer gs://$MY_BUCKET_NAME_1
  
      // install nginx
        sudo apt-get remove -y --purge man-db
        sudo touch /var/lib/man-db/auto-update
        sudo apt-get update
        sudo apt-get install nginx

      //copy the HTML file you created using the Cloud Shell Editor to your virtual machine
        gcloud compute scp index.html first-vm:index.nginx-debian.html --zone=us-central1-b

      //copy the HTML file from your home directory to the document root of the nginx web server:
        sudo cp index.nginx-debian.html /var/www/html
  
  Notes:
    - You can't convert a non-preemptible instance into a preemptible one. This choice must be made at VM creation.

  Quiz
    1. You are considering deploying a solution by using containers on Google Cloud. What Google Cloud solution provides a managed compute platform with native support for containers?
      - Google Kubernetes Engine clusters

    2. You are developing a new product for a customer and need to be mindful of cost and resources. What Google Cloud tools can be used to ensure costs stay manageable before consumption gets too high?
      - Create a new folder inside your organization node, then create projects inside that folder for the resources.

    3. You are developing a new product for a customer and need to be mindful of cost and resources. What Google Cloud tools can be used to ensure costs stay manageable before consumption gets too high?
      - Set up budgets and alerts at the project level.

      - Configure quotas and limits for each product folder.

    4. One of the main characteristics of cloud computing is that resources are elastic. What does that mean?
      - When customers need more resources, they can get more. When they need less, they can scale back.

Module 2: Introduction to Containers and Kubernetes
  - The second section of this course examines software containers and the benefit they bring to application deployment.
  - Learners explore containers and container images, Cloud Build, Kubernetes, and Google Kubernetes Engine.

  Learning Objectives
    - Define the concept of a container and identify uses for containers.
    - Identify the purpose of and use cases for Kubernetes.
    - Outline the concept of Google Kubernetes Engine.
    - Create a container using Cloud Build.

  Containers
    - simply a running instance of an image.
    - isolate workloads is derived from the composition of several technologies
    - containers use a varied set of linux tech:
      - processes
        - containes own virtual memory address space
      - linux namespaces
        - control  what an app can see: process ID num, direcotry trees, IP addr and more
      - cgroups
        - control what an app can use: max cpu time consumption, memory, I/O BW and etc.
      - union file sys
        - efficiently encapsulate applications and their dependencies into a set of clean, minimal layers

    Indiv servers build apps
      Dedicated server:
        App code
        dependencies
        kernel
        hardware
      
      Cons:
        - deploment is in months
        - low utilization
        - not portable

    Hypervisors create and manage VM
      VM:
        App code
        dependencies
        kernel
        hardware + hypervisors

      Cons:
        deployment in mins
        hypervisor/ specification
        not isolated tied to OS

      Fix:
        1. Software engineering policies
          - need to be updated occasionally

        2. Integration tests
          - can cause novel failure modes that are hard to troubleshoot
          - slows down development

    VM-centric way:
      VM:     VM:
      App code  App code
      dep       dep
      kernel    kernel
        Hardware + hypervisor

      Cons:
        - kernel update is slow    
        - redundant OS

    User space abstraction and containers
      VM
        App         App
        User space  User space
        dep         dep
        
        container runtime
          - a software that knows how to launch a container from a container Images

          container layer
            - adds a new writable layer on top of the underlying layers 
            - all changes made to running container are written to this thin writable layer

        
        kernel
        
        hardware + hypervisor

    Containers
      - lightweight sys. in user space.
        - don't carry full OS
      - can be sched or integrated tightly w/ underlying sys
      - can be created and shut down quickly
      - don't boot an entrie VM
      - initialize an OS for each app
      - delivery vehicles for app code
      - stand-alone/resource eff/portable exec packages
      - app centric way to deliver high performance and scalable app
        - container the same and run the same anywhere


    Advantage
      1. They're code-centric way to deliver high-performing, scalable app
      2. They provide access to reliable underlying hardware and software
      3. code will run successfully regardless if it is on a local machine or in production
      4. they make it easier to build app that use the microservices design pattern

    Quiz: Introduction to containers
      1. Which of these problems are containers intended to solve? Mark all that are correct (3 correct answers),
        - Packaging applications in virtual machines can be wasteful.
        - It's difficult to troubleshoot applications when they work on a developer's laptop but fail in production.
        - Applications need a way to isolate their dependencies from one another.

  Container Images
    - ephemeral

    docker
      - an open-source technology that allows you to create and run applications in containers, but it doesn’t offer a way to orchestrate those containers at scale as Kubernetes does
      - no way to orchestrate app at scale
    
    image
      - An application and its dependencies
      - dev can package and ship an app w/o worrying about the sys it will run on

  Qwiklab: Working with Cloud build
  - In this lab you will build a Docker container image from provided code and a Dockerfile using Cloud Build. 
  - You will then upload the container to the Artifact Registry.

  Objectives
    In this lab, you learn how to perform the following tasks:

    1. Use Cloud Build to build and push containers
    2. Use Artifact Registry to store and deploy containers

 Task 1. Confirm that needed APIs are enabled

    Task 2. Building containers with DockerFile and Cloud Build
      //In the Google Cloud Console, click the Details tab for the nginx-1 workload. The Details tab shows more details about the workload including the Pod specification, number and status of Pod replicas and details about the horizontal Pod autoscaler.
          gcloud artifacts repositories create quickstart-docker-repo --repository-format=docker \
    --location=us-east4 --description="Docker repository"
      - Click the Revision History tab. This displays a list of the revisions that have been made to this workload.

      // build the Docker container image in Cloud Build:
        gcloud builds submit --tag us-east4-docker.pkg.dev/${DEVSHELL_PROJECT_ID}/quickstart-docker-repo/quickstart-image:tag1

    Task 3. Building containers with a build configuration file and Cloud Build
      //start a Cloud Build using cloudbuild.yaml as the build configuration file:
        gcloud builds submit --config cloudbuild.yaml

    Task 4. Building and testing containers with a build configuration file and Cloud Build
      //Insert our region value into the yaml file.
        sed -i "s/YourRegionHere/$REGION/g" cloudbuild2.yaml

      //Confirm that your command shell knows that the build failed:
        echo $?

        note:
          The command will reply with a non-zero value. If you had embedded this build in a script, your script would be able to act up on the build's failure.

  Kubernetes
    - an open source platform that helps you orchestrate and manage your cotnainer infra on-premise or in the cloud
      - concetainer-centric management environment
      - automate deployment,scaling, lb, logging, monitoring and other mngmt feautures of containerized app
      - supports declarative configuration
        - deploy desired state when administer infrastructure in spite of success/failures
        - sys desired state is always documented
        - ability to automatically keep sys in a state that you declare
      - allows imperative configuration
        - issue command to change the sys state.
        - use only for quick temp fixes

        Features:
        1. Supports both 
          - stateful(user and session data can be stored persistently) 
          - and stateless(nginx/apache web server) applications
        2. Supports batched jobs and daemon tasks
        3. autoscaling containerized apps
        4. Allows resource limits
          - secify resource request levels and resourve limits for workloads
            - improve overall performance w/in cluster
        5. Extensibility
          - plugins and add-ons
        6. is open source and portable

      Note:
        - allows moving kubernetes workloads freely w/o vendor lock-in

  Google Kubernetes Engine
    - solve "kubernetes is powerful but managing the infra is a full time job"
    - a managed kubernetes service on google infra.
      - helps you deploy, manage and scale kubernetes environments for your containerized app on Google Cloud
      - make it easy to bring kubernetes workload to google cloud
    
    Features
      1. fully managed
      2. container optimized OS
      3. autopilot
        - node
          -  M that host gke clusters
        - mode of operation in GKE which google manages your 
          - cluster config
          - nodes
          - scaling
          - security
          - other preconfig settings
      4. auto repair
        - periodic health check
        - reparirs unhealthy nodes
      5. auto upgrade
        - ensures clusters have the latest stable version of kb8s
        - cluster
          - instatatiate kb8 sys
        - clusters automatically upgraded w/ latest stable ver of kb8s
      6. cluster scaling
        - scale by demand
      7. identity and access mngmt
      8. integrated logging and monitoring
        - how an application is performing
      9. integrated networking(VPC)
        -  load balancers and ingress access for your cluster.
      10. seamless build integration
        - Cloud Build and Artifact Registry
      qq.  google cloud console
        - provides insights into GKE clusters
          - view
          - inspect
          - delete resource
        - dashboard for gke cluster and workloads that you don't have to manage
  
  Quiz:
    1. What is significant about the topmost layer in a container? Choose two options.
      - An application running in a container can only modify the topmost layer.
      - The topmost layer's contents are ephemeral. When the container is deleted, the contents are lost.
      
      - Reading from or writing to the topmost layer requires special software libraries.
      - Reading from or writing to the topmost layer requires special privileges.

    2. When using Kubernetes, you must describe the desired state you want, and Kubernetes's job is to make the deployed system conform to that desired state and keep it there despite failures. What is the name of this management approach?
      - Declarative configuration
      
    3. What is the name for the computers in a Google Kubernetes Engine cluster that run workloads?
      - Nodes
    
Module 3: Kubernetes architecture
  - In this module you’ll learn the components of a Kubernetes cluster and how they work together.
  - Learners deploy a Kubernetes cluster by using Google Kubernetes Engine, deploy Pods to a GKE cluster, and view and manage different Kubernetes objects.

  Introduction
    Learning Objectives    
      - Conceptualize the Kubernetes architecture.
      - Identify how to view and manage Kubernetes objects.
      - Distinguish between Google Kubernetes Engines modes of operation.
      - Deploy a Kubernetes cluster by using GKE.

  Kubernetes concepts
   Two Fundamental components of kb8s operating philosophy:
    1. Kubernetes Object model
      - Object
        - persistent entities of representing the state of the cluster
          - Desired state/Object spec
            - described  by you
          - Current state/Object status
            - described by kb8s control plane
        - represents every thing kubernetes manage
        - can view and change attributes and state

    2. Principle Declarament Management
      - dictates state of the object and bring that state even if it's failure/success

      Watch loop
        - keeping the state you declared

    Two elements to kubernetes objects
      1. Object spec
        - desired state described by us
      2. Object status
        - current state described by kb8s control plane

        kb8s control plane  
          - various sys processes that collaborate to make kb8s cluster work
    
    Kinds of kb8s objects
      1. Pods(Containers in a Pod share resources)
        - basic building block of the standard kubernetes module and they are the 
        - smallest deployable kb8s object 
        - every running container in a kb8s sys is a Pod
        - contains one or more containers 
          - tightly coupled and share resources including networking and storage
          - shares network namespace including IP addr and network products
          - can communicate throug local host IP(127.0.0.1)
        - group of VM instance that share resources contains group containers
        - each pod has a unique IP address
        - pods are not self healing

    Note:
      - kb8s control plane continuouosly monitor state of the cluster, endlessly comparing real stat to what has benn decrlared and remedying state as needed
  
    Quiz
      1. What is the difference between a pod and a container?
        - A pod contains one or more containers.
          - The containers within a pod are tightly coupled with one another and can communicate using the localhost IP address.

  Kubernetes Control Plane/Components
    - a term to refer to the various system processes that collaborate to make a Kubernetes cluster work. 
    - is the fleet of cooperating processes that make a Kubernetes cluster work

    Cooperating processes make a kubernetes cluster work
      1. Control Plane/VM instances
        - coordinate the entire cluster
      2. Nodes/VM instances
        - run pods

    Control Plane Components
      1. kube-apiserver
        - single component that you/client interact w/ directly 
        - accept commands that view/change the state of the cluster
          - including launching pods
        - authenticates incoming req, det whether they are authorized and valid and manages admission control

      2. kubectl
        - commands to view/change state that 
          - connect to kube-apiserve
          - communicate w/ it using the kubernetes API
          - authenticates incoming requests
          - manages admission control

      3. etcd
        - cluster's db
        - reliably store the state of the cluster
          - includes 
            - all of the cluster config data and more dynamic info
            - what nodes are part of the cluster
            - what pods should be running
            -  where they should be running
        - you'll never directly interact w/ etcd
      
      4. kube-scheduler
        - responsible for scheduling pods onto nodes
          - evaluates req of each indiv pod and selecting which node is most suitab;e2
          - when pod object doesn't have an ass to a node
            - it chooses a node and writes the name of that node into the pod objkect
        - features
          - can specify certain pod is only allowed to run on nodes w/ certain memory
          - define affinity specifies
          - define anti0affinity spec
      5. kube-controller-manager
        - continuously monitors the state of the cluster through kube-apo-server
        - it will attempt make the current state equal to the desired state
        - responsible for launching to the pods

        Note:
          - loops of code/controllers
            - manges kb8s objects
            - handle the process of remdiation

        Sample:
          How to keep 3 nginx pods always running
            - gather them into a controller object called deployment

          - Node Controllers
            - montior and respond when a node is offline

        6. kube cloud-manager
          - manages controllers that interact w/ underlying cloud providers
          - responsible for bringing in Google cloud features like LB and storage volumens when you needed them

      Nodes Components
        - runs small family of control plane components
        
        1. kubelet
          - kubernetes agent on each node
          - use by kube-apiserver when it wants to start a pod on a node
          - uses the container runtime to start the pod and monitors its lifecycle, readiness liveliness proves and reports back to kube-api server

          containerd
            - runtime component of Docker
        
        2. kubeproxy
          - maintain the network connectivity amont he pods in a cluster
            - uses FW of iptables built into linux kernel
      Quiz
      1. Which control plane component is the only one with which clients interact directly?
        - kube-apiserver
      
      2. Which control plane component is the cluster's database?
        - etcd
      
      3. What is the role of the kubelet?
        - serve as Kubernetes’s agent on each node

        kube-proxy
          - maintain network connectivity among the Pods in a cluster

         kube cloud-manager 
          - interact with underlying cloud providers
  
  Kubernetes Engine concepts
    Comparison of tw modes of GKE
      1. Autopilot mode
        - manages the entire cluster's infra
          - control plane
          - node-pools
          - nodes
          - node configuration
          - auto-upgrades
          - baseline security config
          - baseline networking config
        - fully managed kb8s cluster bringing tohether the nest pf GKE advances in scaling, securiry and day 2 operations into a google SRE managed and optimized kb8s cluster
        - optimized managed kubernetes w/ hands-off experience
        - less mngmt overhead, but less configuration abilities
        - only pay for what you use(Pod pricing)

      2. Standard mode
        - has all same functionality as Autopilot but your responsible for:
          - configuration of indiv nodes
          - management
          - optimization of the cluster to your requirements
        - managed kb8s w/ configuration flexibility
        - more management overhead but fine grained configuration
        - pay for all provisioned infra regardless of utilization

    Notes
      - In kb8s environment
        - nodes are created externally by cluster admin not by kb8s itself

      - In gke
        - it launch GCE VM instances and register them as nodes automatically
        - pay per hour of life of your nodes(not counting the control plane)
        - By default node machine type
          - e2-medium
            - 2vCPU and 4 GB memory
        - you choose machine type when creating cluster in standard mode
        - max CPU: 416 vCPU cores

        "GKE will never use platform that is older than CPU you specify, and if it picks a newer platform, cost will be the same"
    
      - By default:
        Single zone
          - a cluster launches in a single zone w/ 3 identical nodes all in one node pool

        Regional clusters 
          - single API endpoint for the cluster
          - control planes and nodes are spread across multiple zones/all zones
            - each zone containes control plane and 3 nodes
            - increase one, automatically the same changes w/ other Zone

      - can't convert zonal to regional cluster and vice versa
      - private cluster
        - control plane and nodes are hidden from public internet
      - changes
        - number of nodes can be changed during or after creation of cluster

    GKE feautres:
      1. Node pool
        - is a subset of nodes w/in cluster that share config(amt memory, CPU generation)
        - ensure that workloads run on the right hardware w/in your cluster
        - GKE features
      2. Automatic node upgrades
      3. automatic node repairs
      4. cluster autoscaling


    Quiz  
      1. In GKE clusters, how are nodes provisioned?
        - As Compute Engine virtual machines
      
      2. In GKE, how are control planes provisioned?
        - As abstract parts of the GKE service that are not exposed to Google Cloud customers

      3. What is the purpose of configuring a regional cluster in GKE?
        - To allow applications running in the cluster to withstand the loss of a zone

  Kubernetes Object Management
    Kubernetes Object management
      All objects are identified by:
        - unique name
        - unique identifier

      Manifest files
        - yaml/json format
        - where objects are defined
        
        Required fields:
          1. apiVersion
            - kb8s api version
              - create the obkect
              - maintain backewards compatibility
          2. kind
            - defines the object you want
              - pod
          3. metadata
            - identify object name, unique id, optional namespace like label
              - name is qunique
              - label help you identify and organize objects and subsets of objects
          4. spec

        Best practices:
          - one file to define several drelated objects
          - save Yamls file sin version-controlled repositories
            - easier to track and manage changes when necessary

      Deployment object
        - labeled w/ 3 different key values
          - app, enviroment and stack  

      admin command
        - kubectl get pods --selector=app=nginx

      Pods 
        - are disgned to be ephemeral
        - don't repair themselves and not meant to run forever

      How to to tell kb8s to deploy 3 nginx containerized?
        - declare controller object to mange state of te pods
          - deployments
          - statefulsets
          - dameonsets
          - jobs
        - deployment controller
          - monitor and maitain 3 nginx pods
      
      Resource management for Pods and Containers
        - important that containers have enough resources to run
        - app could use more resources than they should
        - CPU and memory(RAM) resources are the most common resources specified
        
      Namespace
        - allows you to abstract a single physical cluster into multiple clusters
          - test
          - stage
          - prod
        - lets you implemet resource quotas across the cluster

        - 2 initial namespace in a cluster
          1. default
            - pods
            - deployments    
          2. kube-system 
            - objects created by kb8s sys itself
            - configMap
            - secrets
            - controllers
            - deployments
          3. kube-public
            - objects that are publicly readabale to all users
            - tool for disseminating info to everyhtin running in a cluster

          Best practice:
            1. apply namespace at CLI for most flexible
              - kubectl -n demo apply -f mypod.yaml

    A note about deployments and ReplicaSets
      ReplicaSet Object
        - created during rolling upgrade of deployment object
          - increase number of pods in second replicaset while decreases number in first replicaset

    Quiz: Kubernetes Object management
      1. What is the purpose of a Service? Choose all that are true (2 correct answers)
        - To provide a load-balancing network endpoint for Pods
        - To allow you to choose how Pods are exposed

      2. If you are deploying applications in your Pods that need persistent storage, which controller type should you use?
        - StatefulSet

    A note about services
      services
        - provide load balanced access to specified pods

        1. clusterIP
          - exposes the service on an IP address that is only accessible from w/in this cluster.
          - default type.

        2. NodePort
          - exposes the service on the IP addr of each node in the cluster, at a specific port number.

        3. LoadBalancer
          - exposes the service externally, using load balancing service provided by a cloud provider
          - give access to regional network load balancing config by default
          - Ingress object
            - get access to global HTTP(s) load balancing config 

    Controller objects to know about
      1. ReplicaSets
        - ensures that population of pods all identical to one another and running the smae time.
      
      2. Deployments
        - lets you create, update, rollback and scal pods using replicasets as needed to do so
      
      3. Replication Controllers
        - similar to combination of RS and deployments
        - no longer recommended because deployment provide helful frontend to replica

      4. StatefulSets
        - deploy app that maintain local state
        - similar to deployment in that pod use the same container spec.
          - deployment controller are not given persistent identites
          - in statefulsets
            - have unique persistent identities w/ stable network identity and persistent disk storage

      5. DaemonSets
        - if needed certain pods on all nodes
        - ensure that specific pod is always running on all or some subset of the nodes
        - ensure logging agent like fluentd is running on all nodes in the cluster

        daemon
          - non interactive process means running on background
      6. Jobs
        - creates one or more pods required to run a tasks
        - when task is complete, job wil terminate all those pods
        - cronjob
          - runs pods on time based schedule


    Quiz: kubernetes controller objects
      1. In a manifest file for a Pod, in which field do you define a container image for the Pod?
        - spec
      
      2. What are Kubernetes namespaces useful for? Choose all that are correct (2 correct answers).
        - Namespaces let you implement resource quotas across your cluster.
        - Namespaces allow you to use object names that would otherwise be duplicates of one another.

      3. What is the purpose of the Deployment object?
        - To ensure that a defined set of Pods is running at any given time.

    Qwiklab: Deploying GKE Autopilot Clusters
      Overview
        In this lab, you use the Google Cloud Console to build GKE clusters and deploy a sample Pod.

      Objectives
        In this lab, you learn how to perform the following tasks:

          1. Use the Google Cloud Console to build and manipulate GKE Autopilot clusters
          2. Use the Google Cloud Console to deploy a Pod
          3. Use the Google Cloud Console to examine the cluster and Pods

      Task 1. Deploy GKE clusters
        - Clusters can be created across a region or in a single zone. A single zone is the default. 
        -  When you deploy across a region the nodes are deployed to three separate zones and the total number of nodes deployed will be three times higher.

      Task 2. Deploy a sample workload

      Task 3.. View details about workloads in the Google Cloud Console

  Migrate for Anthos
    - used for migrating not contianerized existing app

    Anthos
      - tool for getting workloads into containerized deployment son google cloud
    Migrate for Anthos Introduction
      - move existing app into kb8s environment
      - move and convert workloads into containers
      - workloads can start as physical servers or VMs
      - moves workload compute to container  immediately(<10 min)
      - data can be mirgrated all at once or streamed to the cloud until the app is live in the cloud

    Migrate for Anthos Architecture
      Link to github:

      Step 0: On-premises/cloud
        - uncotainerized app

      Step 1: Migrate for Compute Engine
        - a tool that allows you to bring existing app into VMs on Google Cloud
        - create piplen for streaming or migrating data from on premis or another cloud provider into Google Cloud  
        
        Components
          1. Migrate manager(GCE)
          2. Edge Nodes(GCE)
          3. Cache(GCS)
      
      Step 2: Migrate for Anthos
        - installed on a GKE processing cluster

        Components
          1. Processing Cluster(GKE)
            - namespaces
            - service accounts
            - roles/clustroles
            - rolebingds/clusterrolebindings
            - configmaps
            - services
            - statefulsets
            - dameonsets
            - job
            - storageclass
            - CRD

          2. Artifacts(GCS)

          3. Images(Container Registry)

      Step 3: Production Project
        Components
          1. prod cluster(GKE)
            - app

    Migration Path/steps
      Step 1 - Configure processing cluster
        - install migrate for anthos components inside it

      Step 2 - add migration source
        sources:
          - VMware
          - AWS
          - Azure
          - Google Cloud
      
      Step 3 - generate and review plan
        - create migration object w/ details of the migration that is performed
          - generate template in a yaml file
            - cusotmize to your desire state

      Step 4 - generate artifacts
        - generate image from yaml then container
      
      Step 5 - test

      Step 6 - deploy

    Migrate for Anthos Installation
      1. Procesing cluster
        gcloud contianet --project $PROJECT_ID clusters create $CLUSTER_NAME --zone $CLUSTER_ZONE --username "admin: --cluster-version 1.14 -- machine-type "n1-standard-4 --image-type "UBUNTU" --num-nodes 1 --enable-stackdriver-kubernetes --copes "cloud-platform" --enable-ip-aias --tags="http-server"
          - gke admin to set up the cluster
          - FW rule in place to allow comm between migrate for anthos and migrate for compute engine
        
      1.2. Installing Migrate for Anthos uses migctl
        - CLI
          - migctl setup install

      2. Adding source from compute engine to migrate for anthos
        - migctl source create ce my-ce-src --project my-project --zone zone

      3. Creating migration generates a migration plan
        - migctl migration create test-migration --source my-ce-src --vm-id my-id --intent Image

      4. Executing a migration generates resources and artifacts
        - migctl migration generate-artifacts my-migration
          - processing cluster(GKE) -> docker(GCS) -> yaml files(GCS) -> Container Images(Container Registry)
            - create 2 image one for runnable image for deployment and non-runnable image forupdate contianer image in the future
      
      4.1 Deployment files typically need modification
        - migctl migration get-artifacts test-migration

      4.2 Apply the configuration to deploy the workload
        - kubectl apply -f deployment_spec.yaml

  Summary:
    - object
      - represent every item under kb8s control
      
    - kubernetes controllers keep the cluster state matching the desired state
    - kubernetes consists of family of control plane components, running on the conrol plane and the nodes
    - GKE abstracts away the control plane
    - declare the state you want using manifest files

  Quiz: Kubernetes Architecture
    1. You are designing an application, and you want to ensure that the containers are located as close to each other as possible, in order to minimize latency. Which design decision helps meet this requirement?
      - Place the containers in the same Pod.
    
    2. Google Kubernetes Engine offers two modes of operation: Autopilot and Standard mode. Which one of the options below is a use case for using Standard mode.
      - You require SSH access to nodes.

    3. You want to deploy multiple copies of your application, so that you can load balance traffic across them. How should you deploy this application's Pods to the production Namespace in your cluster?
      - Create a Deployment manifest that specifies the number of replicas that you want to run.

Module 4: Kubernetes Operations
  - The final section of this course introduces the kubectl command, which is the command line utility used to interact with and manage the resources inside Kubernetes clusters
  - Learners are introduced to the concept of introspection, then get practice deploying Google Kubernetes Engine clusters from Cloud Shell.

  Learning Objectives
    - Work with the kubectl command.
    - Inspect the cluster and Pods.
    - View a Pod’s console output.
    - Sign in interactively to a Pod.

  The kubectl command
    - utiility command by admin to control kb8s clusters
    - used to comm w. kube API server on control plane
    - it allows them to make req to cluster
    - det which part of control plane to comm

    First steps
      - kubectl must be configured w/:
        - location
        - credentials

    $HOME/.kube/config
      - config file of kubectl
      - contains
        - list of clusters
        - credentials
          - provided by gcloud command
            //create a Kubernetes cluster
              gcloud container clusters create-auto $my_cluster --region $my_region

            // authenticate shell to allow communicating with that cluster through the kubectl command-line tool
            // connect to kubectl GKE cluster
              gcloud container clusters get-credentials $my_cluster --region $my_region
                - after this command, kubectl auto ref and connect to the said clusters
    Notes
      - kubectl
        - can't create new clusters
          - gcloud can
        - can't change the shape of existing clusters
          - GKE control plane do

        - Use case
          - creating
          - viewing
          - deleting kb8s objects
          - viewing or exporting config files

        - remember to:
          - config kubectkl to right clusters first
          - use --kubeconfig orr --context parameters
        
    Common commands
      //see list of pods in a cluster
        kubetctl get pods

      //get state of the pod in yaml format
        kubectl get pod my-app -o=yaml

      //display list of pods in wide format( displays which node each pod is running on)
        kubectl get pods -o=wide

      //format
        kubectl [command] [Type] [Name] [Flags]

        command
          - what do you want to do
            - get
            - describe
            - logs
            - exec

        Type
          - which type of object
            - pods
            - deployments
            - nodes

        Name
          - what is the object's name
        Flags
          - any special req

  Introspection
    - act of gathering information about the 
      - containers, 
      - pods
      - services, 
      - and other engines that run within the cluster.

    Common debug commands
     1. kubectl get pods
      - tells you whether your pod is running
      - shows pod's phase status
        - Pending
          - accepted a pod but in process/scheduled
            - container is still creating from defined container image 
              - container runtime job
        - running
          - successfully attached to anode
          - containers are created
            - can be 
              - starting
              - restarting
              - running 

        - succeded
          - all containers finished running successfully
          - terminated successfully so they won't be restarting

        - failed
          - container terminated w/ failure and won't be restarting

        - unknown
          - state of the Pod cannot be retrieved
            - comm error bet control plane and kubelet

        - CrashLoopBackOff
          - one of the contianers in the POd exited unexpectedly after restarted at least once
          - pods not config correctly

    2. kubectl describe pod [POD_NAME]
      - investigate pod in detail
      - provides info about a Pod and its containers such as
        - labels
        - resource requirements
        - volumes
        - staus info about pod and container

      - Pod
        - name
        - namespace
        - node name
        - labels
        - status
        - IP addr

      - Container
        - State
          - Waiting
          - running
          - terminated
        
        - images
        - ports
        - commands 
        - restart counts

    3. kubectl exec [POD_NAME] -- [command]
      - run a single command inside a container and view results in your own command shell
      - useful when you want to exec bash command inside your pod


    4. kubectl logs [POD_Name]
      - a way to see what is happening inside a Pod
      - use for troubleshooting
        - reveal errors or debugging messages written by app that run side Pods
      - logs includes
        - stdout
          - standard output on the ocnsole
        - stderr
          - error messages
      - Use cases
        - find containers not running successfully
          -c
            -option for having multiple containers inside a pod
        //Install package to connect to your container command shell
          kubectl exec -it [POD_NAME] -- [command]
          kubectl exec -it my-pod -- /bin/bash
            -i
              - tells kubectl to pass terminal's std input to the container
            -t
              - tells kubectl that input is a TTY

    Best practices
      1. not install software directly into a container
        - changes made by containers to their fs are ephemeral/Temporary
      
      2. Consider building container images that have exactly the software you need
      
      3. The interactive shell will allow you to figure out what needs to be changed

      4. integrate those chnges into container images and redeploy them

  Qwiklab: Deploying GKE Autopilot Clusters from Cloud Shell
    - In this lab, you use the command line to build GKE clusters. 
    - You inspect the kubeconfig file, and you use kubectl to manipulate the cluster.

    Objectives
      In this lab, you learn how to perform the following tasks:

      - Use kubectl to build and manipulate GKE clusters
      - Use kubectl and configuration files to deploy Pods
      - Use Container Registry to store and deploy containers

    Task 1: Deploy GKE Clusters
      // set the environment variable for the zone and cluster name:
        export my_region=us-central1
        export my_cluster=autopilot-cluster-1

      //create a Kubernetes cluster
        gcloud container clusters create-auto $my_cluster --region $my_region

    Task 2: Connect to a GKE cluster
      In Kubernetes, authentication can take several forms. 
      For GKE, authentication is typically handled with 
        - OAuth2 tokens and can be managed through Cloud Identity
        - Access Management across the project as a whole and, optionally, through role-based access control which can be defined and configured within each cluster.

      // authenticate shell to allow communicating with that cluster through the kubectl command-line tool
        gcloud container clusters get-credentials $my_cluster --region $my_region

      .kube directory
        - creates a file named config
          - store the authentication and configuration information.
          - config file is typically called the kubeconfig file.

      // open config file
        vi  ~/.kube/config
        
        - examine all of the authentication
        - endpoint configuration data stored in the file. 
        - Information for the cluster should appear. 
        - The information was populated during cluster creation.

      Note
        - You don't have to run the gcloud container clusters get-credentials command to populate the kubeconfig file for clusters that you created in the same context (the same user in the same environment), because those clusters already have their details populated when the cluster is created.
        - you do have to run the command to connect to a cluster created by another user or in another environment. The command is also an easy way to switch the active context to a different cluster.
        - active context 
          - (the cluster that kubectl commands manipulate) 

    Task 3: Use kubectl to inspect a GKE cluster
      // print content of kubeconfig file
        kubectl config view

      // print out active context cluster
         kubectl cluster-info

      //print out active context
        kubectl config current-context

      //details of cluster contexts
        kubectl config get-contexts

      // change active context
        kubectl config use-context gke_${DEVSHELL_PROJECT_ID}_us-central1_autopilot-cluster-1

      // enable bash autocompletion for kubectl
        source <(kubectl completion bash)

      // all possible command of kubectl
        type kubectl followed by a space and press the Tab key twice

      // outputs all commands starting with "co" or any other text you type
        type kubectl co and press the Tab key twice.

    Task 4: Deploy Pods to GKE clusters
      // deploy nginx as a Pod named nginx-1:
        kubectl create deployment --image nginx nginx-1

      // view all the deployed Pods in the active context cluster:
        kubectl get pods

      // view the resource usage across the nodes of the cluster:
        kubectl top nodes

      // shows similar information across all the deployed Pods in the cluster.
        kubectl top pods

      // set env for pod name
        export my_nginx_pod=nginx-1-695d6d476c-gs97k

        echo $my_nginx_pod

      // view the complete details of the Pod you just created
        kubectl describe pod $my_nginx_pod

      // Push a file into a container
        nano ~/test.html
           This is title
           Hello world 

      // place the file into the appropriate location within the nginx container in the nginx Pod to be served statically:
        kubectl cp ~/test.html $my_nginx_pod:/usr/share/nginx/html/test.html

        - this command copies the test.html file from the local home directory to the /usr/share/nginx/html directory of the first container in the nginx Pod. You can specify other containers in a multi-container Pod by using the -c option, followed by the name of the container.
      
      // Expose the Pod for testing
      
    Task 5: Introspect GKE Pods

  Quiz
    1. You want to use kubectl to configure your cluster, but first you must configure it. Where does the kubectl command store its configuration file?
      - The configuration information is stored in the $HOME/.kube/config file.

    2.You attempt to update a container image to a new version by using the “kubectl describe pod command,” but are not successful. The output of the command shows that the Pod status has changed to “Pending,”the state is shown as “Waiting,” and the reason shown is “ImagePullBackOff.” What is the most probable cause of this error?
      - The container image failed to download.
    
    3.Which command can be used to display error messages from containers in a Pod that are failing to run successfully?
      - kubectl logs 

    4. What command can be used to identify which containers in a Pod are successfully running, and which are failing or having issues?
      - kubectl describe pod 

      - kubectl get pod 

  